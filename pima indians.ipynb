{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now load the file as a matrix of numbers using the NumPy function loadtxt().\n",
    "\n",
    "dataset = pd.read_csv('pima-indians-diabetes.csv',delimiter = ',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "Pregnancies                 768 non-null int64\n",
      "Glucose                     768 non-null int64\n",
      "BloodPressure               768 non-null int64\n",
      "SkinThickness               768 non-null int64\n",
      "Insulin                     768 non-null int64\n",
      "BMI                         768 non-null float64\n",
      "DiabetesPedigreeFunction    768 non-null float64\n",
      "Age                         768 non-null int64\n",
      "Outcome                     768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[['Outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of neurons or nodes in the layer as the first argument, \n",
    "#specify the activation function using the activation argument.\n",
    "#The model expects rows of data with 8 variables (the input_dim=8 argument)\n",
    "# first hidden layer has 12 nodes and uses the relu activation function\n",
    "# second hidden layer has 8 nodes and uses the relu activation function.\n",
    "# output layer has one node and uses the sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and \n",
    "#one output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(12,input_dim = 8,activation = 'relu'))\n",
    "model.add(Dense(8,activation = 'relu'))\n",
    "model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a network means finding the best set of weights to map inputs to outputs in our dataset.\n",
    "# specify the loss function to use to evaluate a set of weights\n",
    "# the optimizer is used to search through different weights for the network\n",
    "#  we will use cross entropy as the loss argument  and is defined in Keras as “binary_crossentropy“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training occurs over epochs and each epoch is split into batches.\n",
    "# Epoch: One pass through all of the rows in the training dataset.\n",
    "# Batch: One or more samples considered by the model within an epoch before weights are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5188 - accuracy: 0.7331\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5362 - accuracy: 0.7305\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.7096\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.7435\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.7591\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7448: 0s - loss: 0.5036 - accuracy: 0.\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7630\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.7396\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.7396\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5260 - accuracy: 0.7292\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7500\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7474\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.7617\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7487\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.7565\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7630\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7552\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.7721\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7513\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.7669: 0s - loss: 0.4996 - accuracy: 0.\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7487\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7630\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7461\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.7682\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7435\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.7604\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7552\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7617\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7721\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.7708\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7747\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.7630\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7500\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7591\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7643\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7617\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7682\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7786\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7630\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7578\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7591\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7591\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7669\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7708\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7604\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7630\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7682\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7682\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7578\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7578\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7695\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7773\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7643\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7747\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7721\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7708\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7669\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7630\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7630\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7656\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7669\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7682\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7786\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7826\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7604\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7643\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7630\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7773\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7695\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7643\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7865\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7852\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7799\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7734\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7773\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7695\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7682\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7852\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7917\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7799\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7708\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.7773\n",
      "Epoch 83/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7812\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7852\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7917\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7865\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7708\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7669\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.7839\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7708\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7865\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7852\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7839\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7878\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7695\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7773\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7760\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7826\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7878\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7878\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7799\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7786\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7852\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7656\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.7839\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.7786\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7669\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7865\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7943\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7773\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7839\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7956\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.7917\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7930\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.7917\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7734\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.7734\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.7812\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7865\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7982\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7969\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7826\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7878\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7760\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.7799\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.7917\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7982\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7669\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.7865\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7812\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7904\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.7878\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7826\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7812\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7839\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7917\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.7852\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.7904\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7760\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.7852\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7839\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7904\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7799\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7786\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7995\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7995\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7826\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.7917\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7786\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21b12548c88>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.8943 - accuracy: 0.5273\n",
      "Epoch 2/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2601 - accuracy: 0.5638\n",
      "Epoch 3/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0444 - accuracy: 0.5990\n",
      "Epoch 4/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.9490 - accuracy: 0.6146\n",
      "Epoch 5/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.8874 - accuracy: 0.6198\n",
      "Epoch 6/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8330 - accuracy: 0.6471\n",
      "Epoch 7/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8143 - accuracy: 0.6419\n",
      "Epoch 8/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.7632 - accuracy: 0.6510\n",
      "Epoch 9/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.7409 - accuracy: 0.6549\n",
      "Epoch 10/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.7048 - accuracy: 0.6667\n",
      "Epoch 11/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.7020 - accuracy: 0.6654\n",
      "Epoch 12/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.6602\n",
      "Epoch 13/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6741 - accuracy: 0.6745\n",
      "Epoch 14/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.6719\n",
      "Epoch 15/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6637 - accuracy: 0.6654\n",
      "Epoch 16/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6766 - accuracy: 0.6693\n",
      "Epoch 17/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6345 - accuracy: 0.6862\n",
      "Epoch 18/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6331 - accuracy: 0.6810\n",
      "Epoch 19/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6332 - accuracy: 0.6576\n",
      "Epoch 20/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.6849\n",
      "Epoch 21/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.6667\n",
      "Epoch 22/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6771\n",
      "Epoch 23/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6146 - accuracy: 0.6888\n",
      "Epoch 24/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6068 - accuracy: 0.6953\n",
      "Epoch 25/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.6992\n",
      "Epoch 26/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6888\n",
      "Epoch 27/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6093 - accuracy: 0.6836\n",
      "Epoch 28/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.6862\n",
      "Epoch 29/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.6966\n",
      "Epoch 30/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.7005\n",
      "Epoch 31/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.6875\n",
      "Epoch 32/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.6823\n",
      "Epoch 33/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.6888\n",
      "Epoch 34/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.6888\n",
      "Epoch 35/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.7018\n",
      "Epoch 36/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.7018\n",
      "Epoch 37/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.7031\n",
      "Epoch 38/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.6927\n",
      "Epoch 39/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.6953\n",
      "Epoch 40/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5846 - accuracy: 0.6979\n",
      "Epoch 41/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.6953\n",
      "Epoch 42/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7109\n",
      "Epoch 43/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7148\n",
      "Epoch 44/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7188\n",
      "Epoch 45/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.7083\n",
      "Epoch 46/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.7148\n",
      "Epoch 47/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7240\n",
      "Epoch 48/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7148\n",
      "Epoch 49/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7109\n",
      "Epoch 50/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7188\n",
      "Epoch 51/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7305\n",
      "Epoch 52/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7240\n",
      "Epoch 53/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7135\n",
      "Epoch 54/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7096\n",
      "Epoch 55/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7122\n",
      "Epoch 56/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7070\n",
      "Epoch 57/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7318\n",
      "Epoch 58/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7253\n",
      "Epoch 59/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7201\n",
      "Epoch 60/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.7266\n",
      "Epoch 61/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7148\n",
      "Epoch 62/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7214\n",
      "Epoch 63/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7318\n",
      "Epoch 64/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7396\n",
      "Epoch 65/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5429 - accuracy: 0.7279\n",
      "Epoch 66/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5346 - accuracy: 0.7409\n",
      "Epoch 67/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5421 - accuracy: 0.7292\n",
      "Epoch 68/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7227\n",
      "Epoch 69/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5369 - accuracy: 0.7161\n",
      "Epoch 70/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5397 - accuracy: 0.7201\n",
      "Epoch 71/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5486 - accuracy: 0.7292\n",
      "Epoch 72/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7253\n",
      "Epoch 73/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.7148\n",
      "Epoch 74/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.7096\n",
      "Epoch 75/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7266\n",
      "Epoch 76/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7383\n",
      "Epoch 77/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5312 - accuracy: 0.7331\n",
      "Epoch 78/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7331\n",
      "Epoch 79/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7305\n",
      "Epoch 80/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5346 - accuracy: 0.7357\n",
      "Epoch 81/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7305\n",
      "Epoch 82/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5256 - accuracy: 0.7344\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5185 - accuracy: 0.7240\n",
      "Epoch 84/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5286 - accuracy: 0.7383\n",
      "Epoch 85/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5340 - accuracy: 0.7279\n",
      "Epoch 86/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5255 - accuracy: 0.7331\n",
      "Epoch 87/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5188 - accuracy: 0.7409\n",
      "Epoch 88/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5265 - accuracy: 0.7500\n",
      "Epoch 89/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5340 - accuracy: 0.7214\n",
      "Epoch 90/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5330 - accuracy: 0.7305\n",
      "Epoch 91/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5295 - accuracy: 0.7305\n",
      "Epoch 92/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.7279\n",
      "Epoch 93/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.7370\n",
      "Epoch 94/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7370\n",
      "Epoch 95/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5187 - accuracy: 0.7344\n",
      "Epoch 96/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5143 - accuracy: 0.7331\n",
      "Epoch 97/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5189 - accuracy: 0.7370\n",
      "Epoch 98/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.7474\n",
      "Epoch 99/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.7448\n",
      "Epoch 100/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5302 - accuracy: 0.7370\n",
      "Epoch 101/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5179 - accuracy: 0.7292\n",
      "Epoch 102/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.7435\n",
      "Epoch 103/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5304 - accuracy: 0.7461\n",
      "Epoch 104/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.7513\n",
      "Epoch 105/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7409\n",
      "Epoch 106/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.7500\n",
      "Epoch 107/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7409\n",
      "Epoch 108/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5132 - accuracy: 0.7526\n",
      "Epoch 109/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7474\n",
      "Epoch 110/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7396\n",
      "Epoch 111/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7448\n",
      "Epoch 112/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5126 - accuracy: 0.7474\n",
      "Epoch 113/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.7435\n",
      "Epoch 114/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7474\n",
      "Epoch 115/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5071 - accuracy: 0.7370\n",
      "Epoch 116/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.7331\n",
      "Epoch 117/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7500\n",
      "Epoch 118/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7500\n",
      "Epoch 119/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.7474\n",
      "Epoch 120/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.7500\n",
      "Epoch 121/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7422\n",
      "Epoch 122/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.7396\n",
      "Epoch 123/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.7643\n",
      "Epoch 124/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.7357\n",
      "Epoch 125/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7409\n",
      "Epoch 126/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7604\n",
      "Epoch 127/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7591\n",
      "Epoch 128/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7474\n",
      "Epoch 129/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7604\n",
      "Epoch 130/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7513\n",
      "Epoch 131/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7526\n",
      "Epoch 132/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7448\n",
      "Epoch 133/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7409\n",
      "Epoch 134/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7604\n",
      "Epoch 135/150\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7357\n",
      "Epoch 136/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7435\n",
      "Epoch 137/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.7552\n",
      "Epoch 138/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.7591\n",
      "Epoch 139/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.7578\n",
      "Epoch 140/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.7474\n",
      "Epoch 141/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7539\n",
      "Epoch 142/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.7240\n",
      "Epoch 143/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.7539\n",
      "Epoch 144/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.7643\n",
      "Epoch 145/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7370\n",
      "Epoch 146/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7669\n",
      "Epoch 147/150\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7474\n",
      "Epoch 148/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.7513\n",
      "Epoch 149/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.7604\n",
      "Epoch 150/150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.7565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21b100d1240>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=150,batch_size=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.7982\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-25-cc892bcd26bd>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU acivation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return max(0.0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_series = [x for x in range(-10,11)]\n",
    "output_series = [relu(x) for x in input_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(input_series,output_series)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
